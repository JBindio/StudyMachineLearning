{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def softmax(x):\n",
    "    c = np.max(x,axis=1).reshape(-1,1)\n",
    "    x = x-c\n",
    "    return np.exp(x)/np.sum(np.exp(x),axis=1).reshape(-1,1)\n",
    "\n",
    "def categorical_crossentropy(y,t):\n",
    "    return np.mean(-t*np.log(y))\n",
    "\n",
    "def make_one(x):\n",
    "    result = np.zeros((x.size, np.unique(x).size))\n",
    "    for idx1,idx2 in enumerate(x):\n",
    "        result[idx1,idx2] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu, Sigmoid, Affine, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None    \n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.mask = (x <=0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx\n",
    "    \n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = ((1-self.out)*self.out)*dout\n",
    "        return dx\n",
    "    \n",
    "class Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.origin_shape = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.origin_shape = x.shape\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = np.dot(dout, self.W.T) \n",
    "        self.dW = np.dot(self.x.T, dout) \n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        dx = dx.reshape(self.origin_shape)\n",
    "        return dx\n",
    "\n",
    "class Loss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self,y,t):\n",
    "        self.y = softmax(y)\n",
    "        self.t = t    \n",
    "        self.loss = categorical_crossentropy(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self,dout=1):\n",
    "        dx = (self.y - self.t)*dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network => Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layers:\n",
    "    def __init__(self):\n",
    "        self.layers = {}\n",
    "    \n",
    "    def add(self,x1,x2,activation):\n",
    "        activation_dict = {\n",
    "            \"sigmoid\" : Sigmoid,\n",
    "            \"relu\" : Relu,\n",
    "            \"softmax\" : Loss,\n",
    "        }\n",
    "        W = np.random.randn(x1,x2)\n",
    "        b = np.zeros(x2)\n",
    "        Affine_layer = \"Affine\"+str(int(len(self.layers)/2+1))\n",
    "        activation_layer = \"activation\"+str(int(len(self.layers)/2+1))\n",
    "        self.layers[Affine_layer] = Affine(W,b)\n",
    "        self.layers[activation_layer] = activation_dict[activation]()\n",
    "\n",
    "    def predict(self,x):\n",
    "        out = x.copy()\n",
    "        ind = 1\n",
    "        layer_len = len(self.layers)\n",
    "        for key,layer in self.layers.items():\n",
    "            if ind < layer_len:\n",
    "                out = layer.forward(out)\n",
    "            ind += 1\n",
    "        return out\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        out = list(self.layers.values())[-1].forward(y,t)\n",
    "        return out\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y,axis=1)\n",
    "        t = np.argmax(t,axis=1)\n",
    "        self.acc = np.sum(y==t)/t.size\n",
    "        return self.acc\n",
    "    \n",
    "    def gradient(self,x,t):\n",
    "        lr = 1e-4\n",
    "        self.loss(x,t)\n",
    "        dout = 1\n",
    "        dout = list(self.layers.values())[-1].backward(dout)\n",
    "        layers = list(self.layers.values())[::-1][1:]\n",
    "        self.layers_key = list(self.layers.keys())[::-1][1:]\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        self.grad = {}\n",
    "        for layer_key in self.layers_key:\n",
    "            if \"Affine\" in layer_key:\n",
    "                self.grad[layer_key] = [self.layers[layer_key].dW, self.layers[layer_key].db]\n",
    "        return self.grad\n",
    "    \n",
    "    def new_gradient(self,x,t):\n",
    "        self.loss(x,t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = list(self.layers.values())[-1].backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        grads = {\n",
    "            \"W3\":self.layers[\"Affine3\"].dW, \"b3\":self.layers[\"Affine3\"].db,\n",
    "            \"W2\":self.layers[\"Affine2\"].dW, \"b2\":self.layers[\"Affine2\"].db,\n",
    "            \"W1\":self.layers[\"Affine1\"].dW, \"b1\":self.layers[\"Affine1\"].db,\n",
    "        }\n",
    "        return grads\n",
    "    \n",
    "    def fit(self,x,t,epochs,lr):\n",
    "        self.lr = lr\n",
    "        self.history = {}\n",
    "        loss = []\n",
    "        accuracy = []\n",
    "        for epoch in range(epochs):\n",
    "            self.gradient(x,t)\n",
    "            loss.append(self.err)\n",
    "            accuracy.append(self.accuracy(x,t))\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'loss : {self.err} === accuracy : {self.accuracy(x,t)}')\n",
    "        self.history[\"loss\"] = loss\n",
    "        self.history[\"accuracy\"] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add(4,10,\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add(10,3,\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add(3,4,\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(100,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = make_one(np.random.randint(0,4,100))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40467358583349095"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.loss(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Affine3': [array([[ 1.24836301,  2.14520321, -2.50675793, -0.88680829],\n",
       "         [ 7.67789456,  5.19293005, -3.65621699, -9.21460762],\n",
       "         [ 4.67921647, -0.15506991, -3.71965605, -0.80449052]]),\n",
       "  array([ 9.12430472,  5.38975319, -7.53032953, -6.98372837])],\n",
       " 'Affine2': [array([[ 3.7012035 , -0.36348058,  5.07028725],\n",
       "         [ 0.36722149, -0.74703103,  2.32579649],\n",
       "         [ 0.28212938,  1.02209394,  0.84033867],\n",
       "         [-0.02259275,  0.04867313,  0.85583793],\n",
       "         [ 3.97318248,  0.20622796,  3.88408897],\n",
       "         [-1.14749635,  1.20900891,  0.68091603],\n",
       "         [ 1.62951106, -0.61567642,  0.53145892],\n",
       "         [ 1.81605387, -0.30284671,  0.47666206],\n",
       "         [-0.78855665,  0.58021444,  0.30388771],\n",
       "         [ 1.45214726,  0.02245651,  2.52236848]]),\n",
       "  array([ 0.59311688, -0.2862043 ,  2.61605603])],\n",
       " 'Affine1': [array([[ 3.07359022,  0.29626232,  2.67754134, -0.35518682, -2.54246433,\n",
       "           1.98977001, -0.39980398, -0.42157326, -0.19311129, -0.8973613 ],\n",
       "         [ 0.43487881, -0.9916763 ,  5.31582331, -1.42623431, -0.95196571,\n",
       "           2.21816024,  0.15152201,  2.09424792,  0.81255315, -0.84767031],\n",
       "         [ 2.04727328,  1.35486771,  0.29176647,  1.25200458, -0.8660283 ,\n",
       "          -1.3235136 , -1.72491721,  0.7402131 ,  3.65263292,  0.30274577],\n",
       "         [ 1.30809579, -3.6228411 , -0.49529719, -1.14615291,  1.3228062 ,\n",
       "           0.0806438 ,  1.26512927, -1.30962583, -1.2254626 ,  0.38985593]]),\n",
       "  array([-1.62995944,  1.41691027, -2.88096213,  2.56277702,  2.25380573,\n",
       "         -0.9438811 , -1.51636137, -2.32774456,  1.05395715,  1.15471191])]}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.gradient(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W3': array([[ 3.65772233,  4.27581985,  4.5304669 ,  3.58067933],\n",
       "        [ 9.54577191,  9.61609326,  9.26202457, 11.81582374],\n",
       "        [ 4.15743213,  4.82219674,  5.15468986,  3.9959718 ]]),\n",
       " 'b3': array([20.27674049, 20.76570176, 20.57938721, 20.8583902 ]),\n",
       " 'W2': array([[ 3.63705958,  2.45760934, -9.1037414 ],\n",
       "        [ 2.31442459,  4.28550013, -4.62948269],\n",
       "        [ 4.57372672,  3.57222659, -2.58805521],\n",
       "        [ 1.20034006,  4.01938163, -3.67136722],\n",
       "        [ 4.17259345,  2.87840938, -6.66873721],\n",
       "        [ 3.91545214,  4.88500862, -6.8470903 ],\n",
       "        [ 5.53171182,  4.61161421, -1.93004835],\n",
       "        [ 3.14797777,  3.07564576, -1.7969338 ],\n",
       "        [ 5.45938141,  1.68882714, -4.87480852],\n",
       "        [ 4.50809114,  2.85249517, -8.49722189]]),\n",
       " 'b2': array([ 4.5646162 ,  5.33863465, -7.29669821]),\n",
       " 'W1': array([[ 1.50438558, -3.98478846, -3.41006493,  2.35991827, -0.28144333,\n",
       "         -3.33526662,  2.08310243, -1.21508028,  1.24867354,  1.54611593],\n",
       "        [ 1.46193766,  1.16340574, -5.12638079,  2.28265312,  1.42635569,\n",
       "         -1.242089  ,  2.22484448, -5.06905785, -1.00392399,  0.83688489],\n",
       "        [ 0.95567167,  0.08430313,  1.56683127, -3.63367977, -2.98079082,\n",
       "          3.65982517, -0.49779582,  0.98325788, -3.06155334, -0.3317395 ],\n",
       "        [-1.34283957,  3.73022167, -2.10726733, -0.1271623 ,  0.11209902,\n",
       "          1.0004048 ,  0.00990145,  1.32226614, -0.96771147,  0.4953594 ]]),\n",
       " 'b1': array([ -5.92744759, -10.13770102,   6.03161409,  -6.63639471,\n",
       "          2.79028103,   4.24202345,   5.32650566,   0.54370772,\n",
       "          0.12793618,   0.15140452])}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.new_gradient(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(4,)\n",
      "(10, 3)\n",
      "(3,)\n",
      "(4, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(network.new_gradient(x,t)[\"W3\"].shape)\n",
    "print(network.new_gradient(x,t)[\"b3\"].shape)\n",
    "print(network.new_gradient(x,t)[\"W2\"].shape)\n",
    "print(network.new_gradient(x,t)[\"b2\"].shape)\n",
    "print(network.new_gradient(x,t)[\"W1\"].shape)\n",
    "print(network.new_gradient(x,t)[\"b1\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 1e-4\n",
    "# network.layers[\"Affine3\"].dW -= lr*network.gradient(x,t)[\"Affine3\"][0]\n",
    "# network.layers[\"Affine3\"].db -= lr*network.gradient(x,t)[\"Affine3\"][1]\n",
    "# network.layers[\"Affine2\"].dW -= lr*network.gradient(x,t)[\"Affine2\"][0]\n",
    "# network.layers[\"Affine2\"].db -= lr*network.gradient(x,t)[\"Affine2\"][1]\n",
    "# network.layers[\"Affine1\"].dW -= lr*network.gradient(x,t)[\"Affine1\"][0]\n",
    "# network.layers[\"Affine1\"].db -= lr*network.gradient(x,t)[\"Affine1\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_kernel",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
